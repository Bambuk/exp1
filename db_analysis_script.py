#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –∏ –≤—ã—è–≤–ª–µ–Ω–∏—è –ø—Ä–æ–±–ª–µ–º –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏.
"""

import os
import sys
from datetime import datetime
from pathlib import Path

# Add project root to path
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from sqlalchemy import create_engine, text
from sqlalchemy.orm import sessionmaker

from radiator.core.config import settings
from radiator.core.database import SessionLocal
from radiator.models.tracker import TrackerSyncLog, TrackerTask, TrackerTaskHistory


class DatabaseAnalyzer:
    """–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —Å–æ—Å—Ç–æ—è–Ω–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö."""

    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞."""
        self.db = SessionLocal()

    def __enter__(self):
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        self.db.close()

    def analyze_table_sizes(self):
        """–ê–Ω–∞–ª–∏–∑ —Ä–∞–∑–º–µ—Ä–æ–≤ —Ç–∞–±–ª–∏—Ü."""
        print("üìä –ê–ù–ê–õ–ò–ó –†–ê–ó–ú–ï–†–û–í –¢–ê–ë–õ–ò–¶")
        print("=" * 50)

        query = text(
            """
            SELECT
                schemaname,
                tablename,
                pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) as size,
                pg_total_relation_size(schemaname||'.'||tablename) as size_bytes
            FROM pg_tables
            WHERE schemaname = 'public'
            ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC;
        """
        )

        result = self.db.execute(query)
        for row in result:
            print(f"{row.tablename:<25} {row.size:>10} ({row.size_bytes:,} bytes)")

    def analyze_table_stats(self):
        """–ê–Ω–∞–ª–∏–∑ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Ç–∞–±–ª–∏—Ü."""
        print("\nüìà –°–¢–ê–¢–ò–°–¢–ò–ö–ê –¢–ê–ë–õ–ò–¶")
        print("=" * 50)

        tables = ["tracker_tasks", "tracker_task_history", "tracker_sync_logs"]

        for table in tables:
            try:
                # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π
                count_query = text(f"SELECT COUNT(*) as count FROM {table}")
                count_result = self.db.execute(count_query).fetchone()

                # –†–∞–∑–º–µ—Ä —Ç–∞–±–ª–∏—Ü—ã
                size_query = text(
                    f"""
                    SELECT pg_size_pretty(pg_total_relation_size('{table}')) as size
                """
                )
                size_result = self.db.execute(size_query).fetchone()

                print(f"\n{table}:")
                print(f"  –ó–∞–ø–∏—Å–µ–π: {count_result.count:,}")
                print(f"  –†–∞–∑–º–µ—Ä: {size_result.size}")

            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ —Ç–∞–±–ª–∏—Ü—ã {table}: {e}")

    def analyze_indexes(self):
        """–ê–Ω–∞–ª–∏–∑ –∏–Ω–¥–µ–∫—Å–æ–≤."""
        print("\nüîç –ê–ù–ê–õ–ò–ó –ò–ù–î–ï–ö–°–û–í")
        print("=" * 50)

        query = text(
            """
            SELECT
                t.tablename,
                i.indexname,
                i.indexdef,
                pg_size_pretty(pg_relation_size(i.indexname::regclass)) as size
            FROM pg_indexes i
            JOIN pg_tables t ON i.tablename = t.tablename
            WHERE t.schemaname = 'public'
            ORDER BY t.tablename, pg_relation_size(i.indexname::regclass) DESC;
        """
        )

        result = self.db.execute(query)
        for row in result:
            print(f"\n{row.tablename}.{row.indexname}")
            print(f"  –†–∞–∑–º–µ—Ä: {row.size}")
            print(f"  –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ: {row.indexdef}")

    def analyze_slow_queries(self):
        """–ê–Ω–∞–ª–∏–∑ –º–µ–¥–ª–µ–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω pg_stat_statements)."""
        print("\nüêå –ê–ù–ê–õ–ò–ó –ú–ï–î–õ–ï–ù–ù–´–• –ó–ê–ü–†–û–°–û–í")
        print("=" * 50)

        try:
            query = text(
                """
                SELECT
                    query,
                    calls,
                    total_time,
                    mean_time,
                    rows
                FROM pg_stat_statements
                WHERE query LIKE '%tracker%'
                ORDER BY mean_time DESC
                LIMIT 10;
            """
            )

            result = self.db.execute(query)
            rows = result.fetchall()

            if rows:
                for row in rows:
                    print(f"\n–ó–∞–ø—Ä–æ—Å: {row.query[:100]}...")
                    print(f"  –í—ã–∑–æ–≤–æ–≤: {row.calls}")
                    print(f"  –û–±—â–µ–µ –≤—Ä–µ–º—è: {row.total_time:.2f}ms")
                    print(f"  –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è: {row.mean_time:.2f}ms")
                    print(f"  –°—Ç—Ä–æ–∫: {row.rows}")
            else:
                print("pg_stat_statements –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω –∏–ª–∏ –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö")

        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –º–µ–¥–ª–µ–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤: {e}")

    def analyze_duplicate_history(self):
        """–ê–Ω–∞–ª–∏–∑ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –≤ –∏—Å—Ç–æ—Ä–∏–∏ –∑–∞–¥–∞—á."""
        print("\nüîÑ –ê–ù–ê–õ–ò–ó –î–£–ë–õ–ò–ö–ê–¢–û–í –í –ò–°–¢–û–†–ò–ò")
        print("=" * 50)

        try:
            # –ù–∞–π—Ç–∏ –¥—É–±–ª–∏–∫–∞—Ç—ã
            query = text(
                """
                SELECT
                    task_id,
                    status,
                    start_date,
                    COUNT(*) as duplicate_count
                FROM tracker_task_history
                GROUP BY task_id, status, start_date
                HAVING COUNT(*) > 1
                ORDER BY duplicate_count DESC
                LIMIT 10;
            """
            )

            result = self.db.execute(query)
            rows = result.fetchall()

            if rows:
                print("–ù–∞–π–¥–µ–Ω—ã –¥—É–±–ª–∏–∫–∞—Ç—ã:")
                total_duplicates = 0
                for row in rows:
                    print(
                        f"  Task {row.task_id}, —Å—Ç–∞—Ç—É—Å '{row.status}', –¥–∞—Ç–∞ {row.start_date}: {row.duplicate_count} –∑–∞–ø–∏—Å–µ–π"
                    )
                    total_duplicates += row.duplicate_count - 1

                print(f"\n–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ª–∏—à–Ω–∏—Ö –∑–∞–ø–∏—Å–µ–π: {total_duplicates}")
            else:
                print("–î—É–±–ª–∏–∫–∞—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")

        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {e}")

    def analyze_missing_indexes(self):
        """–ê–Ω–∞–ª–∏–∑ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏—Ö –∏–Ω–¥–µ–∫—Å–æ–≤."""
        print("\n‚ùå –ê–ù–ê–õ–ò–ó –û–¢–°–£–¢–°–¢–í–£–Æ–©–ò–• –ò–ù–î–ï–ö–°–û–í")
        print("=" * 50)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ –ø–æ–ª—è –¥–ª—è –ø–æ–∏—Å–∫–∞
        critical_fields = [
            ("tracker_tasks", "status"),
            ("tracker_tasks", "assignee"),
            ("tracker_tasks", "author"),
            ("tracker_tasks", "team"),
            ("tracker_tasks", "created_at"),
            ("tracker_tasks", "updated_at"),
            ("tracker_task_history", "task_id"),
            ("tracker_task_history", "status"),
            ("tracker_task_history", "start_date"),
            ("tracker_task_history", "end_date"),
        ]

        for table, column in critical_fields:
            try:
                query = text(
                    """
                    SELECT COUNT(*) as count
                    FROM pg_indexes
                    WHERE tablename = :table
                    AND indexdef LIKE :pattern
                """
                )

                result = self.db.execute(
                    query, {"table": table, "pattern": f"%{column}%"}
                ).fetchone()

                if result.count == 0:
                    print(f"‚ö†Ô∏è  –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∏–Ω–¥–µ–∫—Å –¥–ª—è {table}.{column}")
                else:
                    print(f"‚úÖ –ò–Ω–¥–µ–∫—Å –¥–ª—è {table}.{column} —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")

            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ –∏–Ω–¥–µ–∫—Å–∞ {table}.{column}: {e}")

    def analyze_connection_pool(self):
        """–ê–Ω–∞–ª–∏–∑ –ø—É–ª–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π."""
        print("\nüîó –ê–ù–ê–õ–ò–ó –ü–£–õ–ê –°–û–ï–î–ò–ù–ï–ù–ò–ô")
        print("=" * 50)

        try:
            query = text(
                """
                SELECT
                    state,
                    COUNT(*) as count
                FROM pg_stat_activity
                WHERE datname = current_database()
                GROUP BY state
                ORDER BY count DESC;
            """
            )

            result = self.db.execute(query)
            for row in result:
                print(f"{row.state}: {row.count} —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π")

        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –ø—É–ª–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π: {e}")

    def analyze_data_growth(self):
        """–ê–Ω–∞–ª–∏–∑ —Ä–æ—Å—Ç–∞ –¥–∞–Ω–Ω—ã—Ö."""
        print("\nüìà –ê–ù–ê–õ–ò–ó –†–û–°–¢–ê –î–ê–ù–ù–´–•")
        print("=" * 50)

        try:
            # –ê–Ω–∞–ª–∏–∑ –ø–æ –º–µ—Å—è—Ü–∞–º
            query = text(
                """
                SELECT
                    DATE_TRUNC('month', created_at) as month,
                    COUNT(*) as tasks_count
                FROM tracker_tasks
                WHERE created_at >= NOW() - INTERVAL '12 months'
                GROUP BY DATE_TRUNC('month', created_at)
                ORDER BY month;
            """
            )

            result = self.db.execute(query)
            print("–†–æ—Å—Ç –∑–∞–¥–∞—á –ø–æ –º–µ—Å—è—Ü–∞–º:")
            for row in result:
                print(f"  {row.month.strftime('%Y-%m')}: {row.tasks_count:,} –∑–∞–¥–∞—á")

        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ —Ä–æ—Å—Ç–∞ –¥–∞–Ω–Ω—ã—Ö: {e}")

    def get_recommendations(self):
        """–ü–æ–ª—É—á–∏—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏."""
        print("\nüí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –ü–û –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–ò")
        print("=" * 50)

        recommendations = [
            "1. –ö–†–ò–¢–ò–ß–ù–û: –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –º–µ—Ç–æ–¥ _cleanup_duplicate_history() - –∑–∞–≥—Ä—É–∂–∞–µ—Ç –≤—Å–µ –∑–∞–ø–∏—Å–∏ –≤ –ø–∞–º—è—Ç—å",
            "2. –í–´–°–û–ö–ò–ô –ü–†–ò–û–†–ò–¢–ï–¢: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å bulk –æ–ø–µ—Ä–∞—Ü–∏–∏ –≤–º–µ—Å—Ç–æ –ø–æ—à—Ç—É—á–Ω–æ–π –≤—Å—Ç–∞–≤–∫–∏",
            "3. –°–†–ï–î–ù–ò–ô –ü–†–ò–û–†–ò–¢–ï–¢: –î–æ–±–∞–≤–∏—Ç—å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–ª–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∑–∞–¥–∞—á –≤ JSONB –∫–æ–ª–æ–Ω–∫–µ",
            "4. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø—É–ª–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π (—Ç–µ–∫—É—â–∏–µ: pool_size=20, max_overflow=30)",
            "5. –†–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å –ø–∞—Ä—Ç–∏—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã tracker_task_history –ø–æ –¥–∞—Ç–∞–º",
            "6. –î–æ–±–∞–≤–∏—Ç—å —Å–æ—Å—Ç–∞–≤–Ω–æ–π –∏–Ω–¥–µ–∫—Å –¥–ª—è –ø–æ–∏—Å–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: (task_id, status, start_date)",
            "7. –ù–∞—Å—Ç—Ä–æ–∏—Ç—å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –º–µ–¥–ª–µ–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ —á–µ—Ä–µ–∑ pg_stat_statements",
            "8. –†–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å –∞—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç–∞—Ä—ã—Ö –∑–∞–ø–∏—Å–µ–π –∏—Å—Ç–æ—Ä–∏–∏",
        ]

        for rec in recommendations:
            print(f"  {rec}")

    def run_full_analysis(self):
        """–ó–∞–ø—É—Å—Ç–∏—Ç—å –ø–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑."""
        print("üîç –ê–ù–ê–õ–ò–ó –°–û–°–¢–û–Ø–ù–ò–Ø –ë–ê–ó–´ –î–ê–ù–ù–´–•")
        print("=" * 60)
        print(f"–í—Ä–µ–º—è –∞–Ω–∞–ª–∏–∑–∞: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö: {settings.DATABASE_URL_SYNC}")
        print("=" * 60)

        self.analyze_table_sizes()
        self.analyze_table_stats()
        self.analyze_indexes()
        self.analyze_duplicate_history()
        self.analyze_missing_indexes()
        self.analyze_connection_pool()
        self.analyze_data_growth()
        self.analyze_slow_queries()
        self.get_recommendations()

        print("\n‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω")


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è."""
    try:
        with DatabaseAnalyzer() as analyzer:
            analyzer.run_full_analysis()
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
